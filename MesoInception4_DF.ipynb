{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tyler/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from tensorflow.python.keras import optimizers\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, CSVLogger\n",
    "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import print_summary\n",
    "from tensorflow.python.keras.models import Model as KerasModel\n",
    "from tensorflow.python.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout, Reshape, Concatenate, LeakyReLU\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "random.seed(32)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2\" # Choose GPU NUMBERS [0, 1, 2, 3]\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "sess = tf.Session(config=config)\n",
    "K.set_session(sess)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 0 images belonging to 2 classes.\n",
      "Found 0 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    ")\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'dataset/train',# this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=32) \n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        'dataset/val',# this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=32) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Get a batch of data\n",
    "x, y = train_generator.next()\n",
    "\n",
    "# Print the length of labels and the labels themselves\n",
    "print(len(y))\n",
    "print(y)\n",
    "\n",
    "# Print the shape of x[1]\n",
    "print(x.shape)\n",
    "\n",
    "# Print the labels\n",
    "print(y)\n",
    "\n",
    "# Display an image from the batch with its corresponding label\n",
    "plt.imshow(x[0])\n",
    "plt.title(y[0])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_pred(predictions):\n",
    "    pred=[]\n",
    "    for p in predictions:\n",
    "        if p<0.50:\n",
    "             pred.append(0)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "    return pred\n",
    "\n",
    "IMGWIDTH = 256\n",
    "\n",
    "class Classifier:\n",
    "    def __init__(self):\n",
    "        self.model = 0\n",
    "    \n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "    \n",
    "    def get_accuracy(self, x, y):\n",
    "        return self.model.test_on_batch(x, y)\n",
    "    \n",
    "    def load(self, path):\n",
    "        self.model.load_weights(path)\n",
    "\n",
    "\n",
    "class MesoInception4(Classifier):\n",
    "    # def __init__(self, learning_rate = 0.001):\n",
    "    def __init__(self, learning_rate=0.001, dropout_rate=0.5):\n",
    "        self.model = self.init_model(dropout_rate)\n",
    "        optimizer = Adam(lr = learning_rate)\n",
    "        self.model.compile(optimizer = optimizer, loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "        \n",
    "    \n",
    "    def InceptionLayer(self, a, b, c, d):\n",
    "        def func(x):\n",
    "            x1 = Conv2D(a, (1, 1), padding='same', activation='relu')(x)\n",
    "            \n",
    "            x2 = Conv2D(b, (1, 1), padding='same', activation='relu')(x)\n",
    "            x2 = Conv2D(b, (3, 3), padding='same', activation='relu')(x2)\n",
    "            \n",
    "            x3 = Conv2D(c, (1, 1), padding='same', activation='relu')(x)\n",
    "            x3 = Conv2D(c, (3, 3), dilation_rate = 2, strides = 1, padding='same', activation='relu')(x3)\n",
    "            \n",
    "            x4 = Conv2D(d, (1, 1), padding='same', activation='relu')(x)\n",
    "            x4 = Conv2D(d, (3, 3), dilation_rate = 3, strides = 1, padding='same', activation='relu')(x4)\n",
    "\n",
    "            y = Concatenate(axis = -1)([x1, x2, x3, x4])\n",
    "            \n",
    "            return y\n",
    "        return func\n",
    "    \n",
    "    def init_model(self, dropout_rate):\n",
    "        x = Input(shape = (IMGWIDTH, IMGWIDTH, 3))\n",
    "        \n",
    "        x1 = self.InceptionLayer(1, 4, 4, 2)(x)\n",
    "        x1 = BatchNormalization()(x1)\n",
    "        x1 = MaxPooling2D(pool_size=(2, 2), padding='same')(x1)\n",
    "        \n",
    "        x2 = self.InceptionLayer(2, 4, 4, 2)(x1)\n",
    "        x2 = BatchNormalization()(x2)\n",
    "        x2 = MaxPooling2D(pool_size=(2, 2), padding='same')(x2)        \n",
    "        \n",
    "        x3 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x2)\n",
    "        x3 = BatchNormalization()(x3)\n",
    "        x3 = MaxPooling2D(pool_size=(2, 2), padding='same')(x3)\n",
    "        \n",
    "        x4 = Conv2D(16, (5, 5), padding='same', activation = 'relu')(x3)\n",
    "        x4 = BatchNormalization()(x4)\n",
    "        x4 = MaxPooling2D(pool_size=(4, 4), padding='same')(x4)\n",
    "        \n",
    "        y = Flatten()(x4)\n",
    "        y = Dropout(dropout_rate)(y)\n",
    "        y = Dense(16)(y)\n",
    "        y = LeakyReLU(alpha=0.1)(y)\n",
    "        y = Dropout(0.5)(y)\n",
    "        y = Dense(1, activation = 'sigmoid')(y)\n",
    "\n",
    "        return KerasModel(inputs = x, outputs = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "___________________________________________________________________________________________________________________\n",
      "Layer (type)                         Output Shape              Param #       Connected to                          \n",
      "===================================================================================================================\n",
      "input_1 (InputLayer)                 (None, 256, 256, 3)       0                                                   \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                    (None, 256, 256, 4)       16            input_1[0][0]                         \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                    (None, 256, 256, 4)       16            input_1[0][0]                         \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                    (None, 256, 256, 2)       8             input_1[0][0]                         \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                    (None, 256, 256, 1)       4             input_1[0][0]                         \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                    (None, 256, 256, 4)       148           conv2d_2[0][0]                        \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                    (None, 256, 256, 4)       148           conv2d_4[0][0]                        \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                    (None, 256, 256, 2)       38            conv2d_6[0][0]                        \n",
      "___________________________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)          (None, 256, 256, 11)      0             conv2d_1[0][0]                        \n",
      "                                                                             conv2d_3[0][0]                        \n",
      "                                                                             conv2d_5[0][0]                        \n",
      "                                                                             conv2d_7[0][0]                        \n",
      "___________________________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNormaliz (None, 256, 256, 11)      44            concatenate_1[0][0]                   \n",
      "___________________________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)       (None, 128, 128, 11)      0             batch_normalization_1[0][0]           \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)                    (None, 128, 128, 4)       48            max_pooling2d_1[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)                   (None, 128, 128, 4)       48            max_pooling2d_1[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)                   (None, 128, 128, 2)       24            max_pooling2d_1[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)                    (None, 128, 128, 2)       24            max_pooling2d_1[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)                   (None, 128, 128, 4)       148           conv2d_9[0][0]                        \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)                   (None, 128, 128, 4)       148           conv2d_11[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)                   (None, 128, 128, 2)       38            conv2d_13[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)          (None, 128, 128, 12)      0             conv2d_8[0][0]                        \n",
      "                                                                             conv2d_10[0][0]                       \n",
      "                                                                             conv2d_12[0][0]                       \n",
      "                                                                             conv2d_14[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNormaliz (None, 128, 128, 12)      48            concatenate_2[0][0]                   \n",
      "___________________________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)       (None, 64, 64, 12)        0             batch_normalization_2[0][0]           \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)                   (None, 64, 64, 16)        4816          max_pooling2d_2[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNormaliz (None, 64, 64, 16)        64            conv2d_15[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)       (None, 32, 32, 16)        0             batch_normalization_3[0][0]           \n",
      "___________________________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)                   (None, 32, 32, 16)        6416          max_pooling2d_3[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNormaliz (None, 32, 32, 16)        64            conv2d_16[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)       (None, 8, 8, 16)          0             batch_normalization_4[0][0]           \n",
      "___________________________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)                  (None, 1024)              0             max_pooling2d_4[0][0]                 \n",
      "___________________________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)                  (None, 1024)              0             flatten_1[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "dense_1 (Dense)                      (None, 16)                16400         dropout_1[0][0]                       \n",
      "___________________________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)            (None, 16)                0             dense_1[0][0]                         \n",
      "___________________________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)                  (None, 16)                0             leaky_re_lu_1[0][0]                   \n",
      "___________________________________________________________________________________________________________________\n",
      "dense_2 (Dense)                      (None, 1)                 17            dropout_2[0][0]                       \n",
      "===================================================================================================================\n",
      "Total params: 28,725\n",
      "Trainable params: 28,615\n",
      "Non-trainable params: 110\n",
      "___________________________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model= MesoInception4().model\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"MI4_DF_Ebest_new_loss_only.h5\",\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)\n",
    "csv_logger = CSVLogger(\"MI4_DF_train_new_loss_only.csv\", append=True, separator=',')\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.fit_generator(train_generator,\n",
    "                    verbose=2,\n",
    "                    #changed epochs to 1 to make faster\n",
    "                    epochs=1,\n",
    "                    validation_data=validation_generator,\n",
    "                    callbacks=[model_checkpoint_callback,csv_logger])\n",
    "model.save_weights(\"MI4_DF_E50_new_loss_only.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepFake Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "model= MesoInception4()\n",
    "model.load(\"MI4_DF_Ebest_new_loss_only.h5\")\n",
    "model=model.model\n",
    "print_summary(model, line_length=115, positions=None, print_fn=None)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        'dataset/testing',# this is the target directory\n",
    "        target_size=(256, 256),  # all images will be resized to 150x150\n",
    "        class_mode='binary',\n",
    "        shuffle=False,\n",
    "        seed=32) \n",
    "predictions=model.evaluate_generator(test_generator)\n",
    "print(predictions)\n",
    "predictions=model.predict_generator(test_generator)\n",
    "predicted_classes = get_pred(predictions)\n",
    "true_classes = test_generator.classes\n",
    "report = classification_report(true_classes, predicted_classes, digits=4)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gridsearch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "def create_model(learning_rate=0.001, dropout_rate=0.5):\n",
    "    return MesoInception4(learning_rate=learning_rate, dropout_rate=dropout_rate).model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "param_grid = {\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'dropout_rate': [0.3, 0.5, 0.7],\n",
    "    'batch_size': [32, 64, 128],\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    'dataset/train',\n",
    "    target_size=(256, 256),\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=32)\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    'dataset/val',\n",
    "    target_size=(256, 256),\n",
    "    class_mode='binary',\n",
    "    shuffle=True,\n",
    "    seed=32)\n",
    "\n",
    "X_train, y_train = next(train_generator)\n",
    "X_val, y_val = next(validation_generator)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, std, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, std, param))\n",
    "\n",
    "best_model = grid_result.best_estimator_.model\n",
    "best_model.save_weights('best_model_weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
